{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"220318 day1 quick_start.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPu3i3piq1FooLfMBOYnZCT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ğŸ“¢ í•´ë‹¹ ê²Œì‹œë¬¼ì€ íŒŒì´í† ì¹˜ ê³µì‹ íŠœí† ë¦¬ì–¼ ì¤‘ [íŒŒì´í† ì¹˜ ê¸°ë³¸ ìµíˆê¸°(QuickStart)](https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html)ì™€ PyTorchë¡œ ì‹œì‘í•˜ëŠ” ë”¥ ëŸ¬ë‹ ì…ë¬¸ > [ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹](https://wikidocs.net/57165)ë¥¼ ì¬êµ¬ì„±í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."],"metadata":{"id":"5m8QCiqpt0RD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q86tgmZTbz_I"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["íŒŒì´í† ì¹˜ ê°€ì´ë“œ([link](https://tutorials.pytorch.kr/beginner/basics/quickstart_tutorial.html))ë¥¼ ë³´ë©´ì„œ ê° ì½”ë“œê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ì£¼ì„ì„ ë‹¬ì•„ í•´ì„í•˜ì„¸ìš”."],"metadata":{"id":"RqChF3OIcAwd"}},{"cell_type":"markdown","source":["# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"],"metadata":{"id":"1BN0rl-Cb64W"}},{"cell_type":"code","source":["training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"],"metadata":{"id":"kN600hLKb6Jn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(\"Shape of X [N, C, H, W]: \", X.shape)\n","    print(\"Shape of y: \", y.shape, y.dtype)\n","    break"],"metadata":{"id":"XLHSbXOOcTuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1-1. ì‹œê°í™”í•˜ê¸°"],"metadata":{"id":"lNurmNFQdF03"}},{"cell_type":"code","source":["labels_map = {\n","    0: \"T-Shirt\",\n","    1: \"Trouser\",\n","    2: \"Pullover\",\n","    3: \"Dress\",\n","    4: \"Coat\",\n","    5: \"Sandal\",\n","    6: \"Shirt\",\n","    7: \"Sneaker\",\n","    8: \"Bag\",\n","    9: \"Ankle Boot\",\n","}\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n","    img, label = training_data[sample_idx]\n","    figure.add_subplot(rows, cols, i)\n","    plt.title(labels_map[label])\n","    plt.axis(\"off\")\n","    plt.imshow(img.squeeze(), cmap=\"gray\")\n","plt.show()"],"metadata":{"id":"bFmKG35zdTRv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1-2. ì‚¬ìš©ì ì •ì˜ ë°ì´í„°ì…‹ ìƒì„±"],"metadata":{"id":"E6zOkjNsdXYt"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from torchvision.io import read_image\n","\n","from torch.utils.data import Dataset"],"metadata":{"id":"RDtwusBzdbVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n","        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label']) \n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label"],"metadata":{"id":"EdFCYKrKddmp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. ëª¨ë¸ ìƒì„±"],"metadata":{"id":"2QOZvWXLca46"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"],"metadata":{"id":"13McLse6cjgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"id":"V3i9E-JHceCt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2-1. ëª¨ë¸ layer ì‚´í´ë³´ê¸°"],"metadata":{"id":"CCi7mwgDdmma"}},{"cell_type":"markdown","source":["- input data"],"metadata":{"id":"QX6BcIsxeB9q"}},{"cell_type":"code","source":["input_image = torch.rand(3,28,28) \n","print(input_image.size())"],"metadata":{"id":"CWcnjkLAdwGZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- nn.Flatten"],"metadata":{"id":"zbXwBWYveD6G"}},{"cell_type":"code","source":["flatten = nn.Flatten() \n","flat_image = flatten(input_image)\n","print(flat_image.size())"],"metadata":{"id":"Wm1ddvMbdxmL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- nn.Linear"],"metadata":{"id":"f8_l6EK4eF_x"}},{"cell_type":"code","source":["layer1 = nn.Linear(in_features=28*28, out_features=20)\n","hidden1 = layer1(flat_image)\n","print(hidden1.size())"],"metadata":{"id":"TXklOFRKd49O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- nn.ReLU"],"metadata":{"id":"4JZPQ36BeIl9"}},{"cell_type":"code","source":["print(f\"Before ReLU: {hidden1}\\n\\n\")\n","hidden1 = nn.ReLU()(hidden1)\n","print(f\"After ReLU: {hidden1}\")"],"metadata":{"id":"20M_IFZid6d_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- nn.Sequential"],"metadata":{"id":"EyHy_P-eeMvV"}},{"cell_type":"code","source":["seq_modules = nn.Sequential(\n","    flatten,\n","    layer1,\n","    nn.ReLU(),\n","    nn.Linear(20, 10)\n",")\n","input_image = torch.rand(3,28,28)\n","logits = seq_modules(input_image)"],"metadata":{"id":"rGl3KgtUd8C-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- nn.Softmax"],"metadata":{"id":"hiCcIBKCePAN"}},{"cell_type":"code","source":["softmax = nn.Softmax(dim=1)\n","pred_probab = softmax(logits)"],"metadata":{"id":"YRZ3x0_Fd8-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Model structure: \", model, \"\\n\\n\")\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"],"metadata":{"id":"9cDJZLLAeAB_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. ìµœì í™”"],"metadata":{"id":"sZ3wAxCicqCT"}},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"],"metadata":{"id":"3LjgwOpNcrwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"],"metadata":{"id":"XzDYxk4qcwo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"54v9huEGczEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"id":"eDyOQnwLc2Tv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°"],"metadata":{"id":"96ReaP2yc47f"}},{"cell_type":"code","source":["torch.save(model.state_dict(), \"model.pth\")\n","print(\"Saved PyTorch Model State to model.pth\")"],"metadata":{"id":"U2yt8Dorc6Ll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = NeuralNetwork()\n","model.load_state_dict(torch.load(\"model.pth\"))"],"metadata":{"id":"ONhbX_cPc9w1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"],"metadata":{"id":"6fRsWsKodAqI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹(Custom Dataset)\n","\n","PyTorchë¡œ ì‹œì‘í•˜ëŠ” ë”¥ ëŸ¬ë‹ ì…ë¬¸ > ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹([link](https://wikidocs.net/57165))ì„ ì½ê³  ì½”ë“œë“¤ì˜ í•´ì„ì„ ì£¼ì„ ë‹¬ì•„ì£¼ì„¸ìš”."],"metadata":{"id":"tEpXyc9CmRoP"}},{"cell_type":"markdown","source":["## 5-1. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ìƒì„±"],"metadata":{"id":"0rf_ZjVXmn2T"}},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset): \n","  def __init__(self):\n","\n","  def __len__(self):\n","\n","  def __getitem__(self, idx): "],"metadata":{"id":"UIRwPFOEegdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5-2. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹(Custom Dataset)ìœ¼ë¡œ ì„ í˜• íšŒê·€ êµ¬í˜„í•˜ê¸°"],"metadata":{"id":"4IcLGhzmml1l"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F"],"metadata":{"id":"MrQ7wVG6mijh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"1jXlerFsmwwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset): \n","  def __init__(self):\n","    self.x_data = [[73, 80, 75],\n","                   [93, 88, 93],\n","                   [89, 91, 90],\n","                   [96, 98, 100],\n","                   [73, 66, 70]]\n","    self.y_data = [[152], [185], [180], [196], [142]]\n","\n","  def __len__(self): \n","    return len(self.x_data)\n","\n","  def __getitem__(self, idx): \n","    x = torch.FloatTensor(self.x_data[idx])\n","    y = torch.FloatTensor(self.y_data[idx])\n","    return x, y"],"metadata":{"id":"bxCe0Pwgmyx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = CustomDataset()\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"],"metadata":{"id":"suz8hAfgm3bO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.nn.Linear(3,1)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "],"metadata":{"id":"tkJMNd_qm3Z4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nb_epochs = 20\n","for epoch in range(nb_epochs + 1):\n","  for batch_idx, samples in enumerate(dataloader):\n","    # print(batch_idx)\n","    # print(samples)\n","    x_train, y_train = samples\n","    # H(x) ê³„ì‚°\n","    prediction = model(x_train)\n","\n","    # cost ê³„ì‚°\n","    cost = F.mse_loss(prediction, y_train)\n","\n","    # costë¡œ H(x) ê³„ì‚°\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","        ))"],"metadata":{"id":"1QkmvhzVm3XN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_var =  torch.FloatTensor([[73, 80, 75]]) \n","pred_y = model(new_var) \n","print(\"í›ˆë ¨ í›„ ì…ë ¥ì´ 73, 80, 75ì¼ ë•Œì˜ ì˜ˆì¸¡ê°’ :\", pred_y) "],"metadata":{"id":"qT6pPu9Vm3Up"},"execution_count":null,"outputs":[]}]}